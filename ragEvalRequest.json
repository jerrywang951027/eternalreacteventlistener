{
  "url": "https://api.salesforce.com/einstein/platform/v1/models/sfdc_ai__DefaultGPT4Omni/chat-generations",
  "method": "POST",
  "headers": {
    "Authorization": "Bearer eyJ0bmsiOiJjb3JlL3Byb2QvMDBEV0IwMDAwMDRsODd0MkFBIiwidmVyIjoiMS4wIiwia2lkIjoiQ09SRV9BVEpXVC4wMERXQjAwMDAwNGw4N3QuMTc1ODY1OTEwNDEyOSIsInR0eSI6InNmZGMtY29yZS10b2tlbiIsInR5cCI6IkpXVCIsImFsZyI6IlJTMjU2In0.eyJzY3AiOiJzZmFwX2FwaSBhcGkiLCJzdWIiOiJ1aWQ6MDA1V0IwMDAwMEZodllyWUFKIiwicm9sZXMiOltdLCJpc3MiOiJodHRwczovL252Y3JtLS1xYXMuc2FuZGJveC5teS5zYWxlc2ZvcmNlLmNvbSIsImNsaWVudF9pZCI6IjNNVkc5elY5Q1NGTmJWYlBPeVVwaVlmY3NUVUxKVUt4NXc2Q1AuWUxfTUhPR1JiQ1d1bVlNUnYzSFVWVW5VX3UuUHFIdnI3REJ1TWZPTnZXQmkyRC4iLCJjZHBfdGVuYW50IjoiYTM2MC9wcm9kL2FmNzczZWVkOTNkYzQwNzFhNDM1NjMxYjExNzhkMzM0IiwiYXVkIjpbImh0dHBzOi8vYXBpLnNhbGVzZm9yY2UuY29tIiwiaHR0cHM6Ly9udmNybS0tcWFzLnNhbmRib3gubXkuc2FsZXNmb3JjZS5jb20iXSwibmJmIjoxNzYyNjU3OTk3LCJtdHkiOiJvYXV0aCIsInNmYXBfcmgiOiJib3Qtc3ZjLWxsbTphd3MtcHJvZDEtdXNlYXN0MS9laW5zdGVpbjIsZWluc3RlaW4tdHJhbnNjcmliZS9FaW5zdGVpbkdQVDphd3MtcHJvZDIxLXVzZWFzdDIvZWluc3RlaW4yLG12cy9FREM6YXdzLXByb2QxLXVzZWFzdDEvZWluc3RlaW4yLGVpbnN0ZWluLWFpLWdhdGV3YXkvRURDOmF3cy1wcm9kMS11c2Vhc3QxL2VpbnN0ZWluMixib3Qtc3ZjLWxsbS9FaW5zdGVpbkdQVDphd3MtcHJvZDIxLXVzZWFzdDIvZWluc3RlaW4yLGVpbnN0ZWluLWFpLWdhdGV3YXkvRWluc3RlaW5HUFQ6YXdzLXByb2QyMS11c2Vhc3QyL2VpbnN0ZWluMixib3Qtc3ZjLWFwaTphd3MtcHJvZDEtdXNlYXN0MS91ZW5nYWdlMSIsInNmaSI6ImIwZDBmZDBkMzUyMTVhMDg2Y2NmZDY2MTMyMDEzMTZkOTNlMjE0ZGE4ZTA4MWQ3N2I5NWMwY2MwMTYzYWFlNzYiLCJzZmFwX29wIjoiRWluc3RlaW5IYXdraW5nQzJDRW5hYmxlZCxFR3B0Rm9yRGV2c0F2YWlsYWJsZSxFaW5zdGVpbkdlbmVyYXRpdmVTZXJ2aWNlLFRhYmxlYXVNZXRyaWNCYXNpY3MsRWluc3RlaW5HUFROQ1AsTUNQU2VydmljZSIsImhzYyI6ZmFsc2UsImNkcF91cmwiOiJodHRwczovL2EzNjAuY2RwLmNkcDEuYXdzLXByb2QxLXVzZWFzdDEuYXdzLnNmZGMuY2wiLCJleHAiOjE3NjI3MDEyMTIsImlhdCI6MTc2MjY1ODAxMn0.LDrMY-uBpbjpWY0v6nCPDaUESxnZONKBCBMrCF7lfOBlSNSII-NBb_qqTv_0j8-fZlvmoBUtzmcvGL-u1crKKEyndAv_9qMpNPNp-tk5S8bwhjKzbUzz8LtRZgshPJ-mV5jO4a5bSlMeft8Qp5jfqjcPBhiIYDBEp_ssfB3yVMjGFK0csH5TICVayvSO5exqN4Hz4cTzzkuUhPxfEqBzYOS8LdJAigRf98xK4xN-W0RESBHU2AdAertu8yRGDoxSANc2kEXeLet6CQp2wbHkEYPq14R4DNVVpEJiHEJXTLOFBatR-cB34NMZgS8zbYHNMlM7GBICi7V291lgQjByGg",
    "Content-Type": "application/json;charset=utf-8",
    "x-sfdc-app-context": "EinsteinGPT",
    "x-client-feature-id": "ai-platform-models-connected-app"
  },
  "body": {
    "messages": [
      {
        "role": "user",
        "content": "Please check how much the returned answer matches the requestion below, \nrate it between 0 to 10 while 0 means lowest matches while 10 means perfect match\nthe question is only one while there are a list of answers which need to be evaulated respectively\nresponse format should be like:\n\nInput Instructions:\n  1. inside Answers section, there will be a list of different answers,  I will need you to evalaute each answer\n   against the same question;\n  2. the list of answers will look like:\n    1.answer1\n    2.answer2\n\noutput Instructions:\n1. for identified matches keywords, they need to really match the keywords from original question match through wildcard characters like XXX or *** can be considered\n2.the response should look like below and each provided answer will have its corresponding evaluate result\n[\n    {\n    \"score\": \"5/10\",\n    \"Matched Keywords\": \"switches,EOL,OS\",\n    \"Reasoning\":\"The answer provided details about the End-of-Life status for certain NVIDIA networking switches, which somewhat matches the requested information regarding \\\"EOL\\\" and \\\"switches.\\\" However, it does not specifically address SN2xxxx series switches or any specific operating system (OS) as mentioned in the question. The response is more general and focused on a different model of switch from NVIDIA rather than providing targeted information about SN2xxxx switches and their associated OS status.\\n\\nFor an accurate answer to be given, the details should have been specifically aligned with the SN2xxxx series and related operating system end-of-life statuses if available.\"\n    },\n    {\n     \"score\": \"7/10\",\n    \"Matched Keywords\": \"SB7700, switches, EOL (End of Life)\",\n    \"Reasoning\":\"The answer provided detailed information on the lifecycle phases for different models including the SB7700 series switches. It mentions that these particular switch models are at an \\\"EOL (End of Life)\\\" phase which directly addresses part of the question regarding the end-of-life status of SB7700 switches.\\n\\nHowever, it does not specifically mention anything about the EOL for the operating system associated with these switches, which was another aspect of the original question. Therefore, while the answer is relevant and informative to some extent, it doesn't fully address all aspects of the query, hence the score of 7/10.\"\n    }\n]\nscore: 5/10\nMatched Keywords: switches/OS\n\nQuestion: EOL of SN2xxxx switches and OS\nAnswers: \n1. Submit Search [NVIDIA Docs Hub Homepage](https://docs.nvidia.com/) [NVIDIA Networking](https://docs.nvidia.com/networking/index.html) [Networking Switches](https://docs.nvidia.com/networking/switches/index.html) [1U EDR SB7XX0 100Gb/s InfiniBand Switch Systems and IB Router Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/SB77X0EDR) --- [Is this page helpful?](https://surveys.hotjar.com/4904bf71-6484-47a7-83ff-4715cceabdb5?utm_source=https://docs.nvidia.com/networking/display/sb77x0edr) PDF You can download a PDF version of the full guide [here](https://docs.nvidia.com/1u-edr-sb7xx0-100gb-s-infiniband-switch-systems-and-ib-router-hardware-user-manual.pdf). Relevant for Models: SB7700, SB7790, SB7800, SB7890, SB7780 and SB7880. **About this Manual** This manual describes the installation and basic use of the NVIDIA InfiniBand EDR 1U switches. **Ordering Information** The following table lists ordering information for the available systems. Please pay attention to the airflow direction when ordering your system. For more details, see [Air Flow](/networking/display/SB77X0EDR/Installation). **Intended Audience** This manual is intended for IT managers and system administrators. **Related Documentation** Document Description InfiniBand Architecture Specification Volume 1, Release 1.2.1, and Volume 2, Release 1.3 The InfiniBand Architecture Specification provided by IBTA. MLNX-OS® User Manual This document contains information regarding the configuration and management of the MLNX-OS® software. See https://docs.nvidia.com/networking/category/mlnxos. Hands-on workshops https://academy.nvidia.com/en/infiniband-customized-training/ On-site/remote services For any tailor-made service, contact: nbu-services-sales@nvidia.com. **Revision History** A list of the changes made to this document are provided in [Document Revision History](/networking/display/SB77X0EDR/Document+Revision+History). Expand System Model NVIDIA SKU Legacy OPN Description Lifecycle Phase SB7700 920-9B010-00FE-0M2 MSB7700-ES2F Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), x86 dual core, standard depth, P2C airflow, Rail Kit EOL (End of Life) 920-9B010-00RE-0M0 MSB7700-ES2R Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), x86 dual core, standard depth, C2P airflow, Rail Kit EOL (End of Life) 920-9B010-00FE-0M0 MSB7700-EB2F Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), x86 dual core, short depth, P2C airflow, Rail Kit EOL (End of Life) SB7790 920-9B010-00FE-0D1 MSB7790-ES2F Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), unmanaged, standard depth, P2C airflow, Rail Kit EOL (End of Life) 920-9B010-00FE-0D0 MSB7790-EB2F Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), unmanaged, Short depth, P2C airflow, Rail Kit EOL (End of Life) 920-9B010-00RE-0D0 MSB7790-ES2R Switch-IB™ based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), unmanaged, standard depth, C2P airflow, Rail Kit EOL (End of Life) SB7800 920-9B110-00FE-0M3 MSB7800-ES2F Switch-IB™ 2 based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), x86 dual core, standard depth, P2C airflow, Rail Kit LTB (Last Time Buy) 920-9B110-00RE-0M0 MSB7800-ES2R Switch-IB™ 2 based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), x86 dual core, standard depth, C2P airflow, Rail Kit LTB (Last Time Buy) SB7890 920-9B110-00FE-0D0 MSB7890-ES2F Switch-IB™ 2 based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), unmanaged, standard depth, P2C airflow, Rail Kit LTB (Last Time Buy) 920-9B110-00RE-0D0 MSB7890-ES2R Switch-IB™ 2 based EDR InfiniBand 1U Switch, 36 QSFP28 ports, 2 Power Supplies (AC), unmanaged, standard depth, C2P airflow, Rail Kit LTB (Last Time Buy) SB7780 920-9B010-00FE-0M1 MSB7780-ES2F SwitchIB™-based 36-port QSFP28 EDR 1U Managed InfiniBand router system with anon-blocking switching capacity of 7Tb/s. 2PS, Standard depth, P2C airflow EOL (End of Life) SB7880 920-9B110-00FE-0M1 MSB7880-ES2F Switch-IB 2 based 36-port QSFP28 EDR 1U router, 2 Power Supplies (AC), x86 dual core, standard depth, P2C* airflow, Rail Kit LTB (Last Time Buy) 920-9B110-00RE-0M1 MSB7880-ES2R Switch-IB 2 based 36-port QSFP28 EDR 1U router, 2 Power Supplies (AC), x86 dual core, standard depth, C2P* airflow, Rail Kit LTB (Last Time Buy) InfiniBand Top-of-Rack/Fixed-Configuration Switches Developer / Engineer Dev / IT Operations Networking / Communications Networking NVIDIA Networking © Copyright 2023, NVIDIA. Last updated on Oct 1, 2019. Topics * [1U EDR SB7XX0 100Gb/s InfiniBand Switch Systems and IB Router Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/SB77X0EDR) * [Introduction](https://docs.nvidia.com/networking/display/SB77X0EDR/Introduction) * [Installation](https://docs.nvidia.com/networking/display/SB77X0EDR/Installation) * [Static Rail Kit](https://docs.nvidia.com/networking/display/SB77X0EDR/Static+Rail+Kit) * [Telescopic Rail Kit](https://docs.nvidia.com/networking/display/SB77X0EDR/Telescopic+Rail+Kit) * [Cable Installation](https://docs.nvidia.com/networking/display/SB77X0EDR/Cable+Installation) * [Initial Power On](https://docs.nvidia.com/networking/display/SB77X0EDR/Initial+Power+On) * [System Bring-Up of Managed Systems](https://docs.nvidia.com/networking/display/SB77X0EDR/System+Bring-Up+of+Managed+Systems) * [FRU Replacements](https://docs.nvidia.com/networking/display/SB77X0EDR/FRU+Replacements) * [Software Management](https://docs.nvidia.com/networking/display/SB77X0EDR/Software+Management) * [Interfaces](https://docs.nvidia.com/networking/display/SB77X0EDR/Interfaces) * [LED Notifications](https://docs.nvidia.com/networking/display/SB77X0EDR/LED+Notifications) * [Inventory Pull-out Tab](https://docs.nvidia.com/networking/display/SB77X0EDR/Inventory+Pull-out+Tab) * [Troubleshooting](https://docs.nvidia.com/networking/display/SB77X0EDR/Troubleshooting) * [Specifications](https://docs.nvidia.com/networking/display/SB77X0EDR/Specifications) * [Appendixes](https://docs.nvidia.com/networking/display/SB77X0EDR/Appendixes) * [Accessory and Replacement Parts](https://docs.nvidia.com/networking/display/SB77X0EDR/Accessory+and+Replacement+Parts) * [Thermal Threshold Definitions](https://docs.nvidia.com/networking/display/SB77X0EDR/Thermal+Threshold+Definitions) * [Interface Specifications](https://docs.nvidia.com/networking/display/SB77X0EDR/Interface+Specifications) * [Disassembly and Disposal](https://docs.nvidia.com/networking/display/SB77X0EDR/Disassembly+and+Disposal) * [Switch Safety Warnings (Multiple Languages)](https://docs.nvidia.com/networking/display/SB77X0EDR/Switch+Safety+Warnings+(Multiple+Languages)) * [Document Revision History](https://docs.nvidia.com/networking/display/SB77X0EDR/Document+Revision+History)\n2. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, or SN4700, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n3. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, or SN4700, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n4. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, SN4700, SN5400, or SN5600, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n5. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, SN4700, SN5400, or SN5600, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n6. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, SN4700, SN5400, or SN5600, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n7. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, SN4700, SN5400, or SN5600, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n8. [A newer version](/networking-ethernet-software/cumulus-linux-515/) of this product documentation is available. If you are redirected to the main page of the user guide, then this page might have been renamed or removed. # System Power In certain situations, you might need to power off the switch instead of rebooting. To power off the switch, run the `cl-poweroff` command, which shuts down the switch. ``` cumulus@switch:~$ sudo cl-poweroff ``` Alternatively, you can run the Linux `poweroff` command, which gracefully shuts down the switch (the switch LEDs stay on). On certain switches, such as the NVIDIA SN2201, SN2010, SN2100, SN2100B, SN3420, SN3700, SN3700C, SN4410, SN4600C, SN4600, SN4700, SN5400, or SN5600, the switch reboots instead of powering off. ``` cumulus@switch:~$ sudo poweroff ```\n9. 1U EDR SB7XX0 100Gb/s InfiniBand Switch Systems and IB Router Hardware User Manual (EOL) - NVIDIA Docs\n10. Reset- FastB2B- PriDiscTmr- SecDiscTmr- DiscTmrStat- DiscTmrSERREn- Capabilities: [60] Express (v2) Downstream Port (Slot+), MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0 ExtTag- RBE+ DevCtl: CorrErr- NonFatalErr- FatalErr- UnsupReq- RlxdOrd- ExtTag- PhantFunc- AuxPwr- NoSnoop- MaxPayload 128 bytes, MaxReadReq 128 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #1, Speed 32GT/s, Width x2, ASPM not supported ClockPM- Surprise+ LLActRep+ BwNot- ASPMOptComp+ LnkCtl: ASPM Disabled; Disabled- CommClk- ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 8GT/s (downgraded), Width x2 (ok) TrErr- Train- SlotClk+ DLActive+ BWMgmt- ABWMgmt- ``` ### [Enumeration](#src-4103229342_PCIe-Enumeration) The next stage is PCIe enumeration, a process by which software discovers all devices present in the PCIe fabric. This is accomplished by reading the first register of every possible device address to determine which devices respond. The first register contains the vendor ID and device ID, which uniquely identify the device. PCIe enumeration occurs twice during boot: once by UEFI and then again by Linux. Devices detected during Linux PCIe enumeration are listed by `lspci`. If a device appears here, it indicates that the device is present in the system and has responded correctly to a configuration read. However, this does not guarantee the functionality of the device or its associated driver. ### [Resource Allocation](#src-4103229342_PCIe-ResourceAllocation) After enumeration, the OS performs PCIe resource allocation. If resource allocation fails, some devices may become unavailable to the OS. There are three types of PCIe resources: * I/O space * Bus numbers * Memory space The BlueField platform does not support PCIe I/O space, leaving bus numbers and memory space as the primary considerations. The system supports 255 buses, making exhaustion of this resource unlikely. However, insufficient PCIe memory space can lead to errors, which are often logged in `dmesg`. Copy Copied! ``` [ 0.781698] pci 0000:21:00.0: BAR 6: no space for [mem size 0x00100000 pref] [ 0.781700] pci 0000:21:00.0: BAR 6: failed to assign [mem size 0x00100000 pref] [ 0.781703] pci 0000:21:00.1: BAR 6: no space for [mem size 0x00100000 pref] [ 0.781705] pci 0000:21:00.1: BAR 6: failed to assign [mem size 0x00100000 pref] ``` There are two types of PCIe memory space: * 32-bit memory space – BlueField-3 supports 2 GB, ranging from `0x7FFF_0000_0000` to `0x7FFF_7FFF_FFFF`. * 64-bit memory space – BlueField-3 supports 128 TB, ranging from `0x8000_0000_0000` to `0xFFFF_FFFF_FFFF`. Despite the large capacity of 64-bit memory space, exhaustion is still possible. This can occur due to devices that support a limited number of address bits or alignment requirements, which may leave large chunks of address space unusable. If memory space allocation fails, reviewing `/proc/iomem` can be helpful. This file lists all available memory ranges and their allocation status for each device. Depending on the Linux configuration, it may either retain the resource allocation performed by UEFI or reallocate resources independently. This behavior can be controlled using the kernel command-line options `pci=realloc=on` or `pci=realloc=off`. ### [Device Drivers](#src-4103229342_PCIe-DeviceDrivers) If enumeration and resource allocation succeed but the device services are still not available, then the issue is likely with the driver. If `lspci -v` shows a line labeled `Kernel driver in use` or `Kernel modules`, then the device driver is successfully attached to that device. In the following example, it is the NVMe driver: Copy Copied! ``` # lspci -v -s 6:0.0 06:00.0 Non-Volatile memory controller: KIOXIA Corporation NVMe SSD Controller BG4 (DRAM-less) (prog-if 02 [NVM Express]) Subsystem: KIOXIA Corporation NVMe SSD Controller BG4 (DRAM-less) Physical Slot: 0 Flags: bus master, fast devsel, latency 0, IRQ 61, IOMMU group 6 Memory at 7fff00200000 (64-bit, non-prefetchable) [size=16K] Capabilities: [40] Express Endpoint, MSI 00 Capabilities: [80] Power Management version 3 Capabilities: [90] MSI: Enable- Count=1/32 Maskable+ 64bit+ Capabilities: [b0] MSI-X: Enable+ Count=32 Masked- Capabilities: [100] Advanced Error Reporting Capabilities: [150] Virtual Channel Capabilities: [260] Latency Tolerance Reporting Capabilities: [300] Secondary PCI Express Capabilities: [400] L1 PM Substates Kernel driver in use: nvme Kernel modules: nvme ``` If that line is missing, then the driver is either missing or the attachment failed. In either case, searching for the name of the driver in the `dmesg` output should provide more information. ### [UEFI Enumeration](#src-4103229342_PCIe-UEFIEnumeration) If debugging from Linux is difficult or not available, the UEFI Internal Shell can be used to see the results of PCIe enumeration as done by UEFI. To enter the shell, press `Esc` on the console when UEFI starts to boot. From the menu, select **Boot Manager** and then scroll down to **EFI Internal Shell**. The relevant commands are `pci`, `devices`, and `drivers`. The `help` command will provide usage information for each command. Example `pci` command output: Copy Copied! ``` Shell> pci Seg Bus Dev Func --- --- --- ---- 00 00 00 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device A2DA Prog Interface 0 00 01 00 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device 197B Prog Interface 0 00 02 00 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device 197B Prog Interface 0 00 02 03 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device 197B Prog Interface 0 00 03 00 00 ==> Network Controller - Ethernet controller Vendor 15B3 Device A2DC Prog Interface 0 00 03 00 01 ==> Network Controller - Ethernet controller Vendor 15B3 Device A2DC Prog Interface 0 00 04 00 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device 197B Prog Interface 0 00 05 00 00 ==> Bridge Device - PCI/PCI bridge Vendor 15B3 Device 197B Prog Interface 0 00 06 00 00 ==> Mass Storage Controller - Non-volatile memory subsystem Vendor 1E0F Device 0001 Prog Interface 2 ``` ## [Missing PCIe Devices](#src-4103229342_PCIe-MissingPCIeDevices) If running `lspci` on the BlueField produces no output and all PCIe devices are missing, this indicates that the device is in Livefish mode. In this case, the NIC firmware must be reinstalled. ## [Insufficient Power on the PCIe Slot](#src-4103229342_PCIe-InsufficientPoweronthePCIeSlot) If you see the error `Insufficient power on the PCIe slot` in `dmesg`, consult the \"Specifications\" page of your BlueField device's [hardware user guide](https://docs.nvidia.com/networking/dpu-doca/index.html) to ensure that it is receiving the appropriate power supply. To check the power capacity of your host's PCIe slots, execute the command `lspci -vvv | grep PowerLimit`. For instance: Copy Copied! ``` # lspci -vvv | grep PowerLimit Slot #6, PowerLimit 75.000W; Interlock- NoCompl- Slot #1, PowerLimit 75.000W; Interlock- NoCompl- Slot #4, PowerLimit 75.000W; Interlock- NoCompl- ``` Note This command is not supported by all host vendors or types. ## [Obtaining the Complete PCIe Device Description](#src-4103229342_PCIe-ObtainingtheCompletePCIeDeviceDescription) The `lspci` command may not display the complete descriptions of NVIDIA PCIe devices connected to the host system. For example: Copy Copied! ``` # lspci | grep -i Mellanox a3:00.0 Infiniband controller: Mellanox Technologies Device a2d6 (rev 01) a3:00.1 Infiniband controller: Mellanox Technologies Device a2d6 (rev 01) a3:00.2 DMA controller: Mellanox Technologies Device c2d3 (rev 01) ``` To obtain the full descriptions of these devices, run: Copy Copied! ``` # update-pciids ``` Once the PCIe device ID database has been updated, the `lspci` command should display detailed information for each device. For example: Copy Copied! ``` # lspci | grep -i Mellanox a3:00.0 Infiniband controller: Mellanox Technologies MT42822 BlueField-2 integrated ConnectX-6 Dx network controller (rev 01) a3:00.1 Infiniband controller: Mellanox Technologies MT42822 BlueField-2 integrated ConnectX-6 Dx network controller (rev 01) a3:00.2 DMA controller: Mellanox Technologies MT42822 BlueField-2 SoC Management Interface (rev 01) ``` ## [Managing Two BlueField Platforms in the Same Server](#src-4103229342_PCIe-ManagingTwoBlueFieldPlatformsintheSameServer) This example demonstrates the procedure for managing two BlueField platforms installed in the same server. The process is similar when managing additional platforms. This example assumes that the RShim package is already installed on the host server. ### [Configuring Management Interface on Host](#src-4103229342_PCIe-ConfiguringHostServerSide) Note This example applies only to CentOS and RHEL operating systems. 1. Create a `br_tmfifo` interface configuration file. Run: Copy Copied! ``` vim /etc/sysconfig/network-scripts/ifcfg-br_tmfifo ``` Add the following content to the file: Copy Copied! ``` DEVICE=\"br_tmfifo\" BOOTPROTO=\"static\" IPADDR=\"192.168.100.1\" NETMASK=\"255.255.255.0\" ONBOOT=\"yes\" TYPE=\"Bridge\" ``` 2. Create a configuration file for the first BlueField platform (`tmfifo_net0`). Run: Copy Copied! ``` vim /etc/sysconfig/network-scripts/ifcfg-tmfifo_net0 ``` Add the following content to the file: Copy Copied! ``` DEVICE=tmfifo_net0 BOOTPROTO=none ONBOOT=yes NM_CONTROLLED=no BRIDGE=br_tmfifo ``` 3. Create a configuration file for the second BlueField platform (`tmfifo_net1`). Run: Copy Copied! ``` vim /etc/sysconfig/network-scripts/ifcfg-tmfifo_net1 ``` Add the following content to the file: Copy Copied! ``` DEVICE=tmfifo_net1 BOOTPROTO=none ONBOOT=yes NM_CONTROLLED=no BRIDGE=br_tmfifo ``` 4. Define rules for the `tmfifo_net` interfaces: Run: Copy Copied! ``` vim /etc/udev/rules.d/91-tmfifo_net.rules ``` 5. Restart the network to apply the changes. Run: Copy Copied! ``` # /etc/init.d/network restart ``` Expected output: Copy Copied! ``` Restarting network (via systemctl): [ OK ] ``` ### [Configuring BlueField Platform Side](#src-4103229342_PCIe-ConfiguringBlueFieldPlatformSide) BlueField platforms are shipped with the following factory default configurations for `tmfifo_net0`. Address Value MAC 00:1a:ca:ff:ff:01 IP 192.168.100.2 If more than one BlueField platform is in use, the default MAC and IP addresses must be modified. #### [Updating the RShim Network MAC Address](#src-4103229342_PCIe-UpdatingtheRShimNetworkMACAddress) Note This procedure applies to Ubuntu/Debian (with `sudo`), and CentOS BFB installations. It only affects `tmfifo_net0` on the Arm side. 1. Use a Linux console application (e.g., `screen` or `minicom`) to log into each BlueField platform. For example: Copy Copied! ``` # sudo screen /dev/rshim<0|1>/console 115200 ``` 2. Create a configuration file for the `tmfifo_net0` MAC address: Copy Copied! ``` # sudo vi /etc/bf.cfg ``` 3. Insert the new MAC address into the `bf.cfg` file: Copy Copied! ``` NET_RSHIM_MAC=00:1a:ca:ff:ff:03 ``` 4. Apply the new MAC address: Copy Copied! ``` sudo bfcfg ``` 5. Repeat this process for the second BlueField platform, ensuring each one uses a unique MAC address. Info The Arm processor must be rebooted for the changes to take effect. To avoid unnecessary reboots, it is recommended to update the IP address before restarting the Arm. Note For a comprehensive list of the supported parameters to customize `bf.cfg` during BFB installation, refer to the \"bf.cfg Parameters\" section in the \"[Customizing BlueField Software Deployment Using bf.cfg](https://docs.nvidia.com/networking/display/bluefieldbsp490/customizing+bluefield+software+deployment+using+bf-cfg)\" page. #### [Updating an IP Address](#src-4103229342_PCIe-UpdatingIPAddressUpdatinganIPAddress) * For Ubuntu: 1. Edit the `50-cloud-init.yaml` file to update the `tmfifo_net0` IP address: Copy Copied! ``` sudo vim /etc/netplan/50-cloud-init.yaml ``` Modify the entry as follows: Copy Copied! ``` tmfifo_net0: addresses: - 192.168.100.2/30 # Change to: - 192.168.100.3/30 ``` 2. Reboot the Arm. Run: Copy Copied! ``` sudo reboot ``` 3. Repeat this process for the second BlueField platform, ensuring each one has a unique IP address. Info The Arm processor must be rebooted for the changes to take effect. It is recommended to update the MAC address before restarting the Arm to minimize reboots. * For CentOS: 1. Edit the `ifcfg-tmfifo_net0` file: Copy Copied! ``` # vim /etc/sysconfig/network-scripts/ifcfg-tmfifo_net0 ``` 2. Update the `IPADDR` field: Copy Copied! ``` IPADDR=192.168.100.3 ``` 3. Reboot the Arm processor or apply the changes: Copy Copied! ``` reboot ``` Alternatively, use `netplan apply`. 4. Repeat this process for the second BlueField DPU, ensuring a unique IP address is assigned. Info The Arm processor must be rebooted for the changes to take effect. It is recommended to update the MAC address before restarting the Arm to minimize reboots. © Copyright 2025, NVIDIA. Last updated on Jul 27, 2025.\n11. ## InfiniBand and Ethernet switch and gateway/router solutions for accelerating the data center, HPC, AI, industrial and scientific applications. * [InfiniBand Switches](#hw-documentation) * [Ethernet Switches](#ethernet-switches) * [SW & Other Resources](#sw-other-resources) InfiniBand ToR/Fixed-Conf. Switches HW Manuals [Q3200-RA/Q3400-RA XDR 800Gb/s InfiniBand Switch Systems User Manual](https://docs.nvidia.com/networking/display/XDRSwitchesHWUM) [QM97XX 1U NDR 400Gbps InfiniBand Switch Systems User Manual](https://docs.nvidia.com/networking/display/QM97X0PUB) QM97XX 1U NDR 400Gbps InfiniBand Switch Systems User Manual [QM87xx 1U HDR 200Gb/s InfiniBand Switch Systems User Manual](https://docs.nvidia.com/networking/display/QM87XX) [1U EDR SB7XX0 100Gb/s InfiniBand Switch Systems and IB Router Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/SB77X0EDR) Gateways, Routers & Long Haul Systems HW Manuals [NVIDIA Skyway InfiniBand-to-Ethernet Gateway User Manual](https://docs.nvidia.com/networking/display/skywayum) [1U EDR SB7XX0 100Gb/s InfiniBand Switch Systems and IB Router Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/SB77X0EDR) [NVIDIA MetroX-3 XC TQ8400 Long-haul 1U Appliance User Manual](https://docs.nvidia.com/networking/display/MetroX3) [TQ8x00 MetroX®-2 HDR 200Gb/s InfiniBand Switch Systems User Manual](https://docs.nvidia.com/networking/display/TQ8x00) Modular InfiniBand Switches HW Manuals [NVIDIA CS8500 800 Port HDR Switch System User Manual (EOL)](https://docs.nvidia.com/networking/display/CS8500SYSUM) [CS7520 216-Port EDR InfiniBand Switch-IB™ Series Switch Platform Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/CS7520EDR) [CS7500 648-Port EDR InfiniBand Switch-IB™ Series Switch Platform Hardware User Manual (EOL)](https://docs.nvidia.com/networking/display/CS7500EDR) Ethernet Switches HW Manuals [NVIDIA Spectrum-4 SN5000 2U Switch Systems Hardware User Manual](https://docs.nvidia.com/networking/display/sn5000) [NVIDIA Spectrum-3 SN4000 1U and 2U Switch Systems Hardware User Manual](https://docs.nvidia.com/networking/display/SN4000) [NVIDIA Spectrum-2 SN3000 1U and 2U Switch Systems Hardware User Manual](https://docs.nvidia.com/networking/display/sn3000um) [NVIDIA Spectrum SN2201/M OOB Switch Systems Hardware User Manual](https://docs.nvidia.com/networking/display/SN2201SwitchesUM) [NVIDIA Spectrum SN2000 1U Switch Systems Hardware User Manual](https://docs.nvidia.com/networking/display/sn2000pub) Switch Software OS & Firmware [Switch Software](https://docs.nvidia.com/networking/software/switch-software/index.html) [Switch Firmware](https://docs.nvidia.com/networking/software/switch-firmware/index.html) OEM Reference Guides Guides [IBM & NVIDIA Networking Solutions Reference Guide](https://docs.nvidia.com/networking/display/IBMMLNXSRG) [Lenovo & NVIDIA Networking Solutions Reference Guide](https://docs.nvidia.com/networking/display/LMSRG) [HPE & NVIDIA Networking OEM Solutions Reference Guide](https://docs.nvidia.com/networking/display/HMSRG) [H3C & NVIDIA Networking Reference Solutions Guide](https://docs.nvidia.com/networking/display/MHRG) "
      }
    ]
  }
}